{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audreyemmely/pln/blob/main/pln_lista6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdH0ObvpYJhx"
      },
      "source": [
        "# **Resolução Lista 6**\n",
        "\n",
        "---\n",
        "\n",
        "Audrey Emmely Rodrigues Vasconcelos\n",
        "\n",
        "Karen Nayara Gomes da Silva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "49fJdXrr7jbZ"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#upando train_data e test_data_solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H55rLmyDBk81"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random\n",
        "import nltk\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "import pathlib\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.models import Sequential, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTX97njjFMfF",
        "outputId": "a5f7a963-f0b5-417c-c177-3d96547d4835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('rslp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iyLrIxQ7B3tL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('train_data.txt', sep =':::', header = None, engine = 'python', nrows = 300)\n",
        "df.columns = ['id', 'title', 'genre', 'description']\n",
        "df2 = pd.read_csv('test_data_solution.txt', sep =':::', header = None, engine = 'python', nrows = 300)\n",
        "df2.columns = ['id', 'title', 'genre', 'description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eScG0RcwB4Pl"
      },
      "outputs": [],
      "source": [
        "df3 = pd.concat([df, df2], ignore_index=True)\n",
        "df3.drop('id', axis=1, inplace=True)\n",
        "comedy = df3.loc[df3['genre'].str.contains('comedy')]\n",
        "drama = df3.loc[df3['genre'].str.contains('drama')]\n",
        "dataset = pd.concat([comedy, drama], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ST8YriXuB-xD"
      },
      "outputs": [],
      "source": [
        "def preprocess(description):\n",
        "  description = re.sub(r'\\w*\\d\\w*', '', description) #remove todas as palavras que contêm números\n",
        "  description = re.sub(r'[^a-zA-Z ]', '', description.lower())\n",
        "  return re.sub(r'\\s+', ' ', description) #retira espaços repetidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JvOXznpOB_VU"
      },
      "outputs": [],
      "source": [
        "dataset['processed_description'] = dataset.description.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GxviXDHPCCec"
      },
      "outputs": [],
      "source": [
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "def remove_stopwords(description):\n",
        "    tokenized_text = nltk.word_tokenize(description, language='english')\n",
        "    return \" \".join([token for token in tokenized_text if token not in stop_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tg7JLq5NCEl2"
      },
      "outputs": [],
      "source": [
        "dataset['processed_description_stop'] = dataset.processed_description.apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "eiw7A6WDCGfT",
        "outputId": "f61557ac-7c08-4600-8337-8feacfccc033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a8cf102e-8fdd-4785-a171-bf3ad61c4bc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genre</th>\n",
              "      <th>description</th>\n",
              "      <th>processed_description</th>\n",
              "      <th>processed_description_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Pink Slip\" (2009)</td>\n",
              "      <td>comedy</td>\n",
              "      <td>In tough economic times Max and Joey have all...</td>\n",
              "      <td>in tough economic times max and joey have all...</td>\n",
              "      <td>tough economic times max joey run ideas discov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Babylon Vista (2001)</td>\n",
              "      <td>comedy</td>\n",
              "      <td>Frankie Reno was a child star on a TV show. B...</td>\n",
              "      <td>frankie reno was a child star on a tv show bu...</td>\n",
              "      <td>frankie reno child star tv show thirty years a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Söderpojkar (1941)</td>\n",
              "      <td>comedy</td>\n",
              "      <td>A gang of unemployed itinerant musicians play...</td>\n",
              "      <td>a gang of unemployed itinerant musicians play...</td>\n",
              "      <td>gang unemployed itinerant musicians play south...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tunnel Vision (1976)</td>\n",
              "      <td>comedy</td>\n",
              "      <td>A committee investigating TV's first uncensor...</td>\n",
              "      <td>a committee investigating tvs first uncensore...</td>\n",
              "      <td>committee investigating tvs first uncensored n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"The Young Professionals\" (2015)</td>\n",
              "      <td>comedy</td>\n",
              "      <td>Whether it's blocking up mouse holes, running...</td>\n",
              "      <td>whether its blocking up mouse holes running f...</td>\n",
              "      <td>whether blocking mouse holes running landlords...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>Future Weather (2012)</td>\n",
              "      <td>drama</td>\n",
              "      <td>When her single mom runs off to California, L...</td>\n",
              "      <td>when her single mom runs off to california la...</td>\n",
              "      <td>single mom runs california lauduree passionate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>Six Minutes to Midnight (????)</td>\n",
              "      <td>drama</td>\n",
              "      <td>Summer 1939. Influential families in Nazi Ger...</td>\n",
              "      <td>summer influential families in nazi germany h...</td>\n",
              "      <td>summer influential families nazi germany sent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>Jeunes filles en détresse (1939)</td>\n",
              "      <td>drama</td>\n",
              "      <td>Jacqueline is sixteen. Her parents are kept v...</td>\n",
              "      <td>jacqueline is sixteen her parents are kept ve...</td>\n",
              "      <td>jacqueline sixteen parents kept busy mutual ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>Silence (2013/XI)</td>\n",
              "      <td>drama</td>\n",
              "      <td>'Silence' is an intimate portrait of the life...</td>\n",
              "      <td>silence is an intimate portrait of the life o...</td>\n",
              "      <td>silence intimate portrait life ten year old gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>My Perfect Gentleman (????)</td>\n",
              "      <td>drama</td>\n",
              "      <td>Learn how one man struggles to find a way out...</td>\n",
              "      <td>learn how one man struggles to find a way out...</td>\n",
              "      <td>learn one man struggles find way poverty one w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>235 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8cf102e-8fdd-4785-a171-bf3ad61c4bc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8cf102e-8fdd-4785-a171-bf3ad61c4bc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8cf102e-8fdd-4785-a171-bf3ad61c4bc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                  title  ...                         processed_description_stop\n",
              "0                   \"Pink Slip\" (2009)   ...  tough economic times max joey run ideas discov...\n",
              "1                 Babylon Vista (2001)   ...  frankie reno child star tv show thirty years a...\n",
              "2                   Söderpojkar (1941)   ...  gang unemployed itinerant musicians play south...\n",
              "3                 Tunnel Vision (1976)   ...  committee investigating tvs first uncensored n...\n",
              "4     \"The Young Professionals\" (2015)   ...  whether blocking mouse holes running landlords...\n",
              "..                                  ...  ...                                                ...\n",
              "230              Future Weather (2012)   ...  single mom runs california lauduree passionate...\n",
              "231     Six Minutes to Midnight (????)   ...  summer influential families nazi germany sent ...\n",
              "232   Jeunes filles en détresse (1939)   ...  jacqueline sixteen parents kept busy mutual ca...\n",
              "233                  Silence (2013/XI)   ...  silence intimate portrait life ten year old gi...\n",
              "234        My Perfect Gentleman (????)   ...  learn one man struggles find way poverty one w...\n",
              "\n",
              "[235 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLrZXVqZ7l5o"
      },
      "source": [
        "## Questão 1\n",
        "Resolva novamente a segunda questão da 3a lista usando pelo menos duas arquiteturas de redes neurais que utilizem camadas Embedding, convolucionais e \n",
        "LSTM. Compare com os resultados obtidos anteriormente nas lista 3 e 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpXvmJtZ8fAa"
      },
      "source": [
        "## Questão 2\n",
        "Usando sua base de textos:\n",
        "\n",
        "a) Treine uma rede LSTM para gerar texto, que receba uma ou mais palavras\n",
        "de uma frase como entrada. O treinamento deve ser realizado considerando\n",
        "um conjunto supervisionado que gera a próxima palavra de uma sequência\n",
        "de tamanho 4, usando subsequências de sua base.\n",
        "\n",
        "b) Após o treinamento, exiba pelo menos 5 exemplos de textos dados de entrada, e do texto gerado em seguida pela rede treinada. Para cada exemplo, gere pelo menos 10 palavras consecutivamente."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "def get_sequence_of_tokens(description):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(dataset.processed_description)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    input_sequences = []\n",
        "    for line in description:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(dataset.processed_description)"
      ],
      "metadata": {
        "id": "6bY-5WRO96DV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "metadata": {
        "id": "mRMtn4Sw-nUn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "  \n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6dFGDE_5QL",
        "outputId": "b19ccbe4-8523-47cd-e227-616dd858cced"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 660, 10)           57310     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5731)              578831    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 680,541\n",
            "Trainable params: 680,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors, label, epochs=11, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2UzSEHbAIc0",
        "outputId": "e0cfab6e-9aa1-4cfe-f654-ea422677694a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/11\n",
            "750/750 [==============================] - 454s 597ms/step - loss: 7.2160\n",
            "Epoch 2/11\n",
            "750/750 [==============================] - 425s 567ms/step - loss: 6.7974\n",
            "Epoch 3/11\n",
            "750/750 [==============================] - 440s 586ms/step - loss: 6.6510\n",
            "Epoch 4/11\n",
            "750/750 [==============================] - 413s 551ms/step - loss: 6.4953\n",
            "Epoch 5/11\n",
            "750/750 [==============================] - 418s 558ms/step - loss: 6.3433\n",
            "Epoch 6/11\n",
            "750/750 [==============================] - 414s 553ms/step - loss: 6.2013\n",
            "Epoch 7/11\n",
            "750/750 [==============================] - 412s 549ms/step - loss: 6.0516\n",
            "Epoch 8/11\n",
            "750/750 [==============================] - 412s 549ms/step - loss: 5.8795\n",
            "Epoch 9/11\n",
            "750/750 [==============================] - 416s 554ms/step - loss: 5.7024\n",
            "Epoch 10/11\n",
            "750/750 [==============================] - 413s 551ms/step - loss: 5.5229\n",
            "Epoch 11/11\n",
            "750/750 [==============================] - 412s 549ms/step - loss: 5.3551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3799bfc1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len): \n",
        "    #seed_text: string para teste, next_word: qtdd de palavras q quer prever, max_sequence_len: contagem max de seq usada durante o treinamento\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        predicted = model.predict(token_list) \n",
        "        classes = np.argmax(predicted,axis=1)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == classes:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "4SseLskbASO2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (generate_text(\"frankie reno was a child\", 4, model, max_sequence_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlpfz70-ATGA",
        "outputId": "94725f4b-fd0c-4cbb-e1bc-90771de5fd43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frankie Reno Was A Child Of A Young Man\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (generate_text(\"whether its blocking up\", 10, model, max_sequence_len))\n",
        "print (generate_text(\"science and technology\", 10, model, max_sequence_len))\n",
        "print (generate_text(\"awake from a deep sleep\", 10, model, max_sequence_len))\n",
        "print (generate_text(\"first film\", 10, model, max_sequence_len))\n",
        "print (generate_text(\"the sydney opera house\", 10, model, max_sequence_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tfhm_6VFrez",
        "outputId": "1f4407c4-7794-4bd3-f29d-566bf325779a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whether Its Blocking Up A Story Of A Young Man Of The Young Company\n",
            "Science And Technology To A Story Of A Young Man Of The World\n",
            "Awake From A Deep Sleep Of The New World Of The Slack Company In The\n",
            "First Film A Story Of A Young Man Of The World Of\n",
            "The Sydney Opera House In A Russian Man In The New World Of The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questão 3\n",
        "Usando sua base de textos e a biblioteca spaCy, realize as seguintes tarefas:\n",
        "\n",
        "a) Extraia as etiquetas gramaticais (POS) de cada token do seu textos.\n",
        "\n",
        "b) Calcule e plote um gráfico com as frequências de cada tipo gramatical.\n",
        "\n",
        "c) Extraia entidades do tipo pessoa e lugar dos seus textos.\n",
        "\n",
        "d) Identifique e liste as pessoas mais frequentes nos seus textos. Você só deve contar cada entidade 1 vez por documento."
      ],
      "metadata": {
        "id": "EU7F2228KdPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "YtLG_xuW36Iq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_description_list = list(dataset['processed_description_stop'].values)"
      ],
      "metadata": {
        "id": "7g8GsjbM_JlW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_pos = []\n",
        "\n",
        "for phrase in processed_description_list:\n",
        "    doc = nlp(phrase)\n",
        "\n",
        "    for token in doc:        \n",
        "        token_pos.append(token.pos_)\n",
        "\n",
        "token_pos[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnn-0E4N_gAN",
        "outputId": "8b41d0be-1db7-420f-bf78-b7f67eb7e650"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADJ',\n",
              " 'PROPN',\n",
              " 'NOUN',\n",
              " 'PROPN',\n",
              " 'PROPN',\n",
              " 'PROPN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'PROPN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'NUM',\n",
              " 'VERB',\n",
              " 'CCONJ',\n",
              " 'ADJ',\n",
              " 'NOUN']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(24,8))\n",
        "plt.hist(token_pos, bins=16, rwidth=0.5, align='left', color='green')\n",
        "\n",
        "plt.xlabel('Tipo gramatical')\n",
        "plt.ylabel('Quantidade')\n",
        "  \n",
        "plt.title('Frequência de cada tipo gramatical',\n",
        "          fontweight =\"bold\")\n",
        "  \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "pE95g_vQ6Izh",
        "outputId": "6a41bd21-c246-4845-95d1-d42a05f23b1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities_person_gpe = []\n",
        "persons = {}\n",
        "entities_to_search = ['PERSON', 'GPE']\n",
        "\n",
        "for phrase in processed_description_list:\n",
        "    doc = nlp(phrase)\n",
        "\n",
        "    for entity in doc.ents:\n",
        "      entity_persons_in_doc = []\n",
        "\n",
        "    if entity.label_ in entities_to_search:\n",
        "      entities_person_gpe.append((entity.text, entity.label_))\n",
        "      \n",
        "      if entity.label_ == 'PERSON':\n",
        "          entity_persons_in_doc.append(entity.text)\n",
        "      \n",
        "      unique_persons = list(set(entity_persons_in_doc))\n",
        "      \n",
        "      for unique_person in unique_persons:\n",
        "        if unique_person in persons.keys():\n",
        "          persons[unique_person] += 1\n",
        "        else:\n",
        "          persons[unique_person] = 1"
      ],
      "metadata": {
        "id": "bQGbRbWzDSlI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_person_gpe[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q-uPX57F9Iy",
        "outputId": "45ee9f9d-78cd-427c-f220-ba4fd1718967"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hollywood', 'GPE'),\n",
              " ('astrakhan maurice', 'PERSON'),\n",
              " ('las vegas', 'GPE'),\n",
              " ('eve', 'PERSON'),\n",
              " ('herbert marshall', 'PERSON'),\n",
              " ('kenny doug', 'PERSON'),\n",
              " ('theatre company', 'PERSON'),\n",
              " ('standup comedy favorite', 'PERSON'),\n",
              " ('sleepy joe', 'PERSON'),\n",
              " ('mum struggles', 'PERSON'),\n",
              " ('irene falls young ronald', 'PERSON'),\n",
              " ('kim', 'PERSON'),\n",
              " ('hollywood', 'GPE'),\n",
              " ('standup', 'PERSON'),\n",
              " ('john michael', 'PERSON'),\n",
              " ('monte cristo', 'PERSON'),\n",
              " ('susan', 'PERSON'),\n",
              " ('sicilia', 'GPE'),\n",
              " ('sicilia', 'GPE'),\n",
              " ('joe', 'PERSON')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_entities = list([ent[1] for ent in entities_person_gpe])\n",
        "\n",
        "[(entity, get_entities.count(entity)) for entity in set(get_entities)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAtkTOezGzZv",
        "outputId": "d9d7e68f-4155-4421-a0c5-50ba89bc8227"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('GPE', 25), ('PERSON', 76)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_frequent_persons = [(key, value) for key, value in persons.items()]\n",
        "most_frequent_persons.sort(key= lambda person : person[1], reverse=True)\n",
        "most_frequent_persons[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abUUExtxJS20",
        "outputId": "1fd5db81-c92d-4775-ffe1-1eda9d7eec0f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('simon', 4),\n",
              " ('rani', 2),\n",
              " ('minas gerais', 2),\n",
              " ('rick jos young pierrot', 2),\n",
              " ('astrakhan maurice', 1),\n",
              " ('eve', 1),\n",
              " ('herbert marshall', 1),\n",
              " ('kenny doug', 1),\n",
              " ('theatre company', 1),\n",
              " ('standup comedy favorite', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questão 4\n",
        "Estude o tutorial *Character-level recurrent sequence-to-sequence model* disponível em https://keras.io/examples/nlp/lstm_seq2seq/.\n",
        "\n",
        "a) Treine um outro modelo de tradução entre línguas distintas e exiba 5 exemplos de tradução de frases curtas. Você pode encontrar conjuntos de treinamento em http://www.manythings.org/anki/.\n",
        "\n",
        "b) BONUS: Adapte o código para realizar tradução com uma rede *word-level*.\n"
      ],
      "metadata": {
        "id": "Qen9foNaKfnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ],
      "metadata": {
        "id": "OONCI9dSctgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a898efbe-66bb-4e93-946c-216b412ef938"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ],
      "metadata": {
        "id": "cgeHZCxvcxi8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX97IEuZc1rR",
        "outputId": "3b18fcd4-9ad5-4a2d-f94f-10bc4d9bee19"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"I'll remember you forever.\", '[start] Siempre me acordaré de ti. [end]')\n",
            "('He always leaves the window open while he sleeps.', '[start] Siempre deja la ventana abierta mientras duerme. [end]')\n",
            "('I want you to leave my house.', '[start] Quiero que te vayas de mi casa. [end]')\n",
            "(\"I've been waiting for two hours.\", '[start] Llevo dos horas esperando. [end]')\n",
            "('He wiped the sweat from his forehead.', '[start] Él se secó el sudor de su frente. [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vetorizar os dados**"
      ],
      "metadata": {
        "id": "elh2XNt7c71_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ],
      "metadata": {
        "id": "cEzsuvNBdAv9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "LzSjDfIgdPvx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NER61Ltdbk9",
        "outputId": "952e2e95-4534-4785-fa74-b4bc9dc17a23"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construir o modelo**"
      ],
      "metadata": {
        "id": "uNf2pqVWdhZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "IVRSFNAPdp90"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")"
      ],
      "metadata": {
        "id": "90Zl8Hqzdyox"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treinando o modelo**"
      ],
      "metadata": {
        "id": "jVd7vH-feLN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demorou cerca de 1 hora pra rodar (por causa do epochs)\n",
        "transformer.summary()\n",
        "transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=1, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIaGqvtWeM-Y",
        "outputId": "f26dbda3-7dab-4eda-f84e-def5eb486f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding (Position  (None, None, 256)   3845120     ['encoder_inputs[0][0]']         \n",
            " alEmbedding)                                                                                     \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  12959640    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "  72/1302 [>.............................] - ETA: 56:33 - loss: 2.3586 - accuracy: 0.2181"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decodifica as sentanças**"
      ],
      "metadata": {
        "id": "tq4o3AQMeYgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(20):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence.replace('[start] ', '').replace(' [end]', '')\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for i in range(5):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(str(i + 1) + '.')\n",
        "    print('Input sentence:', input_sentence)\n",
        "    print('Decoded sentence:', translated)"
      ],
      "metadata": {
        "id": "7Z4-2wXaeb2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkZ2rKF1CnNO"
      },
      "source": [
        "**Referências**\n",
        "\n",
        "[Beginners Guide to Text Generation using LSTMs](https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms)\n",
        "\n",
        "[English-to-Spanish translation with a sequence-to-sequence Transformer](https://keras.io/examples/nlp/neural_machine_translation_with_transformer/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pln_lista6.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}